{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fExxcm-ma_an"
      },
      "source": [
        "# **MODELO 2 - MODELO DE APRENDIZAJE AUTOMÁTICO BASADO EN REDES NEURONALES CONVOLUCIONALES DE CLASIFICACIÓN MULTICLASE, PARA LA DETECCIÓN AUTOMÁTICA DE EVENTOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGXwFi6jM1eQ"
      },
      "source": [
        "# Imports para REDES NEURONALES\n",
        "import itertools\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from matplotlib import image\n",
        "from scipy.signal import convolve2d\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from PIL import Image, ImageDraw\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vXbX4bf0wEz"
      },
      "source": [
        "# IMP: Asumiremos que tenemos el mismo número de imágenes, N, y que tenemos solo 4 tipos de eventos\n",
        "# Además, el número de trazas de los waterfalls de las 3 opciones, depende de los intervalos que elijamos para hacer el tratamiento de datos correspondiente a cada uno\n",
        "\n",
        "N=250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cYty8czCD2U"
      },
      "source": [
        "# Manual creation of the classes vectors\n",
        "numeroImagenes = N\n",
        "c1 = np.full((1,numeroImagenes), 0)\n",
        "c2 = np.full((1,numeroImagenes), 1)\n",
        "c3 = np.full((1,numeroImagenes), 2)\n",
        "c4 = np.full((1,numeroImagenes), 3)\n",
        "\n",
        "# IMP: Asumiremos que tenemos el mismo número de imágenes, y que tenemos solo 4 tipos de eventos\n",
        "# Además, el número de trazas de los waterfalls de las 3 opciones, depende de los intervalos que elijamos para hacer el tratamiento de datos correspondiente a cada uno\n",
        "classes_V = np.concatenate((c1, c2, c3, c4), axis=1)  # WARNING: transpose, para que funcione asignación de x,y train,test\n",
        "classes_V = np.reshape(classes_V, (4*numeroImagenes,))\n",
        "classes_A = classes_V\n",
        "classes_F = classes_V\n",
        "\n",
        "#print(classes_A)\n",
        "print(np.shape(classes_A))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVikbjnvneHe"
      },
      "source": [
        "## **1 - RED CONVOLUCIONAL (VARIANZA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8iV2nFUn-39"
      },
      "source": [
        "# Load in the data\n",
        "classes = classes_V  \n",
        "numeroImagenes = N\n",
        "\n",
        "for indx, i in enumerate(classes):\n",
        "    if indx == 0:\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/SET 2/Varianza/Ruido/V%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = (np.array([np.loadtxt(filename)])).astype('uint32')\n",
        "    if indx>0 and indx<=(numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/SET 2/Varianza/Ruido/V%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=numeroImagenes and indx<=(2*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/SET 2/Varianza/Ruido + Evento Fijo/V%d_RuidoYEventoFijo.npy\" %(indx+1-numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=2*numeroImagenes and indx<=(3*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/SET 2/Varianza/Ruido + Andar en paralelo/V%d_RuidoYAndarParalelo.npy\" %(indx+1-2*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=3*numeroImagenes and indx<=(4*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/SET 2/Varianza/Ruido + Correr en paralelo/V%d_RuidoYCorrerParalelo.npy\" %(indx+1-3*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwOgMQJ4ozAJ"
      },
      "source": [
        "# Split into data and test\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, classes, test_size = 0.33, random_state = 46)\n",
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj52k63JozwG"
      },
      "source": [
        "# the data is only 2D!\n",
        "# convolution expects height x width x color\n",
        "x_train = np.expand_dims(x_train,-1)  # Añade dimensión para incluir píxel\n",
        "x_test = np.expand_dims(x_test,-1)  # Añade dimensión para incluir píxel\n",
        "# x_train shape\n",
        "print('x_train.shape: ', x_train.shape)  # Por defecto, elegimos 75% de imágenes disponibles para entrenar, y 25% para testear\n",
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "print('number of classes: ', K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc0iBPuIo24J"
      },
      "source": [
        "# Build the model using the TensorFlow 2.0 functional API\n",
        "i = Input(shape=x_train[0].shape)  # Dimensión de las imágenes\n",
        "x = Conv2D(32, (9, 9), strides=2, activation='relu')(i)  # \n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(64, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(128, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "model = Model(i,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDS1TGOo574"
      },
      "source": [
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2AMEgDdo-t2"
      },
      "source": [
        "# Plot loss per iteration\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('lossv.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANGqFWWKpBH6"
      },
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KrSSSCKpFNm"
      },
      "source": [
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm,classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
        "    print('Normalized confusion matrix')\n",
        "  else:\n",
        "    print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm,interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max()/2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "    plt.text(j,i,format(cm[i,j], fmt),\n",
        "             horizontalalignment = 'center',\n",
        "             color = 'white' if cm[i,j] > thresh else 'black')\n",
        "  plt.show()\n",
        "\n",
        "p_test = model.predict(x_test).argmax(axis=1)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE4ZFCqvns0k"
      },
      "source": [
        "## **2 - RED CONVOLUCIONAL (AJUSTE FUNCIONAL)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWLLBFsICDns"
      },
      "source": [
        "# Load in the data\n",
        "classes = classes_A  \n",
        "numeroImagenes = N\n",
        "\n",
        "for indx, i in enumerate(classes):\n",
        "    if indx == 0:\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Ajuste/Ruido/A%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = (np.array([np.loadtxt(filename)])).astype('uint32')\n",
        "    if indx>0 and indx<=(numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Ajuste/Ruido/A%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=numeroImagenes and indx<=(2*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Ajuste/Ruido + Evento Fijo/A%d_RuidoYEventoFijo.npy\" %(indx+1-numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=2*numeroImagenes and indx<=(3*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Ajuste/Ruido + Andar en paralelo/A%d_RuidoYAndarParalelo.npy\" %(indx+1-2*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=3*numeroImagenes and indx<=(4*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Ajuste/Ruido + Correr en paralelo/A%d_RuidoYCorrerParalelo.npy\" %(indx+1-3*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-foVursJ-mcC"
      },
      "source": [
        "# Split into data and test\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, classes, test_size = 0.33, random_state = 46)\n",
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvBcmi5DQuh5"
      },
      "source": [
        "# the data is only 2D!\n",
        "# convolution expects height x width x color\n",
        "x_train = np.expand_dims(x_train,-1)  # Añade dimensión para incluir píxel\n",
        "x_test = np.expand_dims(x_test,-1)  # Añade dimensión para incluir píxel\n",
        "# x_train shape\n",
        "print('x_train.shape: ', x_train.shape)  # Por defecto, elegimos 75% de imágenes disponibles para entrenar, y 25% para testear\n",
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "print('number of classes: ', K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB7PWJdAWY7J"
      },
      "source": [
        "# Build the model using the TensorFlow 2.0 functional API\n",
        "i = Input(shape=x_train[0].shape)  # Dimensión de las imágenes\n",
        "x = Conv2D(32, (9, 9), strides=2, activation='relu')(i)  # \n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(64, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(128, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "model = Model(i,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vkZZJxMWhQ1"
      },
      "source": [
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHwtZBKlZ06T"
      },
      "source": [
        "# Plot loss per iteration\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WEUDcrZ3Vq"
      },
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrzLl7reZ9QB"
      },
      "source": [
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm,classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
        "    print('Normalized confusion matrix')\n",
        "  else:\n",
        "    print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm,interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max()/2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "    plt.text(j,i,format(cm[i,j], fmt),\n",
        "             horizontalalignment = 'center',\n",
        "             color = 'white' if cm[i,j] > thresh else 'black')\n",
        "  plt.show()\n",
        "\n",
        "p_test = model.predict(x_test).argmax(axis=1)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z7DopSlQCrc"
      },
      "source": [
        "## **3 - RED CONVOLUCIONAL (FOURIER)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh29TJXIO-Pg"
      },
      "source": [
        "# Load in the data\n",
        "classes = classes_F  \n",
        "numeroImagenes = N\n",
        "\n",
        "for indx, i in enumerate(classes):\n",
        "    if indx == 0:\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Fourier/Ruido/F%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = (np.array([np.loadtxt(filename)])).astype('uint32')\n",
        "    if indx>0 and indx<=(numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Fourier/Ruido/F%d_SoloRuido.npy\" %(indx+1)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=numeroImagenes and indx<=(2*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Fourier/Ruido + Evento Fijo/F%d_RuidoYEventoFijo.npy\" %(indx+1-numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=2*numeroImagenes and indx<=(3*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Fourier/Ruido + Andar en paralelo/F%d_RuidoYAndarParalelo.npy\" %(indx+1-2*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)\n",
        "    if indx>=3*numeroImagenes and indx<=(4*numeroImagenes-1):\n",
        "        filename = \"/content/drive/MyDrive/TFG_COTDR_Imágenes/Fourier/Ruido + Correr en paralelo/F%d_RuidoYCorrerParalelo.npy\" %(indx+1-3*numeroImagenes)\n",
        "        images = np.concatenate((images,(np.array([np.loadtxt(filename)])).astype('uint32')),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTz1XQtnPZcm"
      },
      "source": [
        "# Split into data and test\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, classes, test_size = 0.33, random_state = 46)\n",
        "x_train, x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9rjMc80O-2Q"
      },
      "source": [
        "# the data is only 2D!\n",
        "# convolution expects height x width x color\n",
        "x_train = np.expand_dims(x_train,-1)  # Añade dimensión para incluir píxel\n",
        "x_test = np.expand_dims(x_test,-1)  # Añade dimensión para incluir píxel\n",
        "# x_train shape\n",
        "print('x_train.shape: ', x_train.shape)  # Por defecto, elegimos 75% de imágenes disponibles para entrenar, y 25% para testear\n",
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "print('number of classes: ', K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymmck8QAO_HC"
      },
      "source": [
        "# Build the model using the TensorFlow 2.0 functional API\n",
        "i = Input(shape=x_train[0].shape)  # Dimensión de las imágenes\n",
        "x = Conv2D(32, (9, 9), strides=2, activation='relu')(i)  # \n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(64, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(128, (9, 9), strides=2, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "model = Model(i,x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn1bgnGvO_Py"
      },
      "source": [
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "r = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DI3ZS1CP2kh"
      },
      "source": [
        "# Plot loss per iteration\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label = 'val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0SPXhdFP2xH"
      },
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label = 'val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyozsKgkP25L"
      },
      "source": [
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm,classes,\n",
        "                          normalize=False,\n",
        "                          title='Matriz de confusión',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
        "    print('Normalized confusion matrix')\n",
        "  else:\n",
        "    print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm,interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max()/2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "    plt.text(j,i,format(cm[i,j], fmt),\n",
        "             horizontalalignment = 'center',\n",
        "             color = 'white' if cm[i,j] > thresh else 'black')\n",
        "  plt.show()\n",
        "\n",
        "p_test = model.predict(x_test).argmax(axis=1)\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}